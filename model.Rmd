---
title: "Regression model"

output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    code_folding: hide
---

```{r setup, include = FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(caret)
library(purrr)
library(tidyverse)
```



# Data Set Splitting

We firstly divide the data set into training and testing sets.

```{r}
data=readRDS("data_for_model.rds") 
training_data <- filter(data, year >= 2018 & year <= 2020)|>select(-c(state,year))
testing_data <- filter(data, year == 2021)|>select(-c(state,year))
```

# Multiple Linear Regression

## Model Selection

Explain why multiple linear regression was chosen.
Describe the mathematical form of the model and assumptions.

## Full model-Linear regression 

```{r}
model <- lm(death_rate ~ employment+hc_exp+income+edu_level+cardio_rate+smoke_rate+elder_rate, data = training_data)
summary(model)
```

## Backwards Elimination

```{r}
backward_result=step(model, direction='backward')
```


## Selected value

```{r}
selected_model <- lm(death_rate ~ hc_exp + edu_level + cardio_rate + elder_rate, data = training_data)
summary(selected_model)
```

```{r}
residuals <- resid(selected_model)

qqnorm(residuals)
qqline(residuals, col = "red")
```

## Model Performation

### Cross Validation for RMSE

```{r}
library(modelr)
# generate a cv dataframe 
cv_df <-
  crossv_mc(training_data, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
# fit the model to the generated CV dataframe
cv_df <-
  cv_df %>% 
  mutate(
    model  = map(train, ~lm(death_rate ~employment+hc_exp+income+edu_level+cardio_rate+smoke_rate+elder_rate, data = .x)),
    rmse = map2_dbl(model, test, ~rmse(model = .x, data = .y)))
# plot the prediction error
cv_df %>% 
  select(rmse) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse") %>% 
  ggplot(aes(x= model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "Prediction Errors For Our Model Under CV",
    x = "Model lm",
    y = "Prediction Errors"
  ) 
```

加入bootstrap


# Random Forest Model

## Model Selection

Justify the choice of the random forest model.
Explain the fundamental principles of the model.

```{r}
library(randomForest)

rf_model <- randomForest(death_rate ~employment+hc_exp+income+edu_level+cardio_rate+smoke_rate+elder_rate, data = training_data)
```

## Model Performation

```{r}
library(modelr)
# generate a cv dataframe 
cv_df <-
  crossv_mc(training_data, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
# fit the model to the generated CV dataframe
cv_df <-
  cv_df %>% 
  mutate(
    model  = map(train, ~randomForest(death_rate ~employment+hc_exp+income+edu_level+cardio_rate+smoke_rate+elder_rate, data = .x)),
    rmse = map2_dbl(model, test, ~rmse(model = .x, data = .y)))
# plot the prediction error
cv_df %>% 
  select(rmse) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse") %>% 
  ggplot(aes(x= model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "Prediction Errors For Our Model Under CV",
    x = "Model rf",
    y = "Prediction Errors"
  ) 
```

```{r}
# R²
rf_predictions <- predict(rf_model, training_data)
r_squared <- cor(training_data$death_rate, rf_predictions)^2
print(paste("R²:", r_squared))
```

```{r}
library(randomForest)
library(boot)

# 假设 your_data 是您的数据集
# 假设响应变量是 target

# 自举函数
bootstrap_r2 <- function(data, indices) {
  boot_data <- data[indices, ]
  # 训练随机森林模型
  model <- randomForest(death_rate ~employment+hc_exp+income+edu_level+cardio_rate+smoke_rate+elder_rate, data = boot_data)
  # 预测
  predictions <- predict(model, boot_data)
  # 计算R²值
  r_squared <- cor(boot_data$death_rate, predictions)^2
  return(r_squared)
}

# 执行自举
set.seed(123)  # 为了可重复性
results <- boot(data = training_data, statistic = bootstrap_r2, R = 10)

# 绘制R²分布
hist(results$t, breaks = 30, main = "Bootstrap Distribution of R²", xlab = "R² Values")

```

## Prediction

```{r}
# Assuming you have actual_values, predicted_values_lm, and predicted_values_rf

# Create a scatter plot
plot(testing_data$death_rate, predict(rf_model, testing_data), main = "Linear Regression Predictions", xlab = "Actual Values", ylab = "Predicted Values", col = "black")
```



## Results and Discussion

```{r}
importance_values <- importance(rf_model)


print(importance_values)

library(plotly)

importance_values <- importance(rf_model)

feature_importance <- data.frame(Feature = rownames(importance_values), 
                                 Importance = importance_values[,1]) %>%
  arrange(Importance) %>% 
  mutate(Feature = factor(Feature, levels = Feature)) 

plot_ly(feature_importance, x = ~Importance, y = ~Feature, type = 'bar', orientation = 'h') %>%
  layout(title = "Feature Importance from Random Forest Model",
         xaxis = list(title = "Importance"),
         yaxis = list(title = "Feature"))
```


数值较高的特征被视为更重要，diabetes_rate，rpp，obesity_rate 最重要 - 待解释

Summarize the performance of multiple linear regression and random forest models.

Interpret model results and important features.
Discuss limitations of the study and future work.














